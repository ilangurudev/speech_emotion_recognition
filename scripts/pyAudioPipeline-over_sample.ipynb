{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import audioFeatureExtraction as aF\n",
    "from pathlib import Path\n",
    "\n",
    "from pandas_ml import ConfusionMatrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn import pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer, recall_score\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('../data/')\n",
    "df_labels = labels = pd.read_csv(path_data/'ComParE2018_AtypicalAffect.txt', sep=\"\\t\")\n",
    "df_labels['subset'] = df_labels['file_name'].str.split('_').apply(lambda x: x[0])\n",
    "df_labels.head()\n",
    "\n",
    "\n",
    "X_train, y_train = ((df_labels.loc[(df_labels['subset']=='train')][['file_name']]), \n",
    "                    df_labels.loc[df_labels['subset']=='train']['emotion'])\n",
    "\n",
    "X_devel, y_devel = (df_labels.loc[df_labels['subset']=='devel'][['file_name']], \n",
    "                    df_labels.loc[df_labels['subset']=='devel']['emotion'])\n",
    "\n",
    "X_test, y_test = (df_labels.loc[df_labels['subset']=='test'][['file_name']], \n",
    "                    df_labels.loc[df_labels['subset']=='test']['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ros = RandomOverSampler(random_state=0)\n",
    "# X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "# np.unique(y_resampled, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadRawData(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_c = X.copy()\n",
    "        df_sample_data = X_c['file_name'].apply(lambda x: audioBasicIO.readAudioFile(path_data/'wav'/x))\n",
    "        X_c['sample_rate'] = df_sample_data.apply(lambda x: x[0])\n",
    "        X_c['raw_data'] = df_sample_data.apply(lambda x: x[1])\n",
    "        X_c['duration'] = X_c['raw_data'].apply(lambda x: x.size)/X_c['sample_rate']\n",
    "        return X_c\n",
    "        \n",
    "rrd = ReadRawData()\n",
    "X_train = rrd.fit_transform(X_train)\n",
    "X_devel = rrd.transform(X_devel)\n",
    "X_test =rrd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyAudioAnalysisFeaturesFactory(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 limit_to=4, #parameter to control where to truncate (or pad)\n",
    "                 pad=['resize', 'zero', 'mean', 'stat'][0], # what kind of padding to use\n",
    "                 frame_size=0.05, #PyAudio default\n",
    "                 frame_step=0.025,#PyAudio default\n",
    "                 keep_duration=True, #to keep duration as a feature\n",
    "                 print_every=50\n",
    "                ):\n",
    "        self.limit_to, self.pad = limit_to, pad\n",
    "        self.frame_size, self.frame_step = frame_size, frame_step\n",
    "        self.keep_duration = keep_duration\n",
    "        self.key = f'{limit_to}_{pad}_{frame_size}_{frame_step}_{keep_duration}'\n",
    "        self.print_every = print_every\n",
    "\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X):\n",
    "        self.counter = 0\n",
    "        X_c = X.copy().reset_index(drop=True)\n",
    "        if self.pad == 'stat':\n",
    "            features = X_c.apply(lambda x: self.add_features_functionals((x['sample_rate'], \n",
    "                                                                          x['raw_data'])), \n",
    "                                 axis=1)\n",
    "            features = pd.DataFrame(features.values.tolist())\n",
    "        else:\n",
    "            features = X_c.apply(lambda x: self.add_features((x['sample_rate'], x['raw_data'])), axis=1)\n",
    "            # these steps are just for getting the column names\n",
    "            x = X_c['raw_data'].iloc[0]\n",
    "            fs = X_c['sample_rate'].iloc[0]\n",
    "            s, t = aF.stFeatureExtraction(np.resize(x,(fs*self.limit_to,)),\n",
    "                                          fs,\n",
    "                                          self.frame_size*fs,\n",
    "                                          self.frame_step*fs)\n",
    "            col_names = np.array([f'{name}_{i}' for i in range(s.shape[1]) for name in t]).reshape(-1)\n",
    "            features = pd.DataFrame(features.values.tolist(), columns=col_names)\n",
    "        \n",
    "        if self.keep_duration:\n",
    "            features['duration'] = X_c['duration']\n",
    "        return features.astype(np.float32)\n",
    "            \n",
    "    def counter_print(self):\n",
    "        if self.counter%self.print_every == 0:\n",
    "            print(self.counter, end=' ')\n",
    "        self.counter += 1\n",
    "    \n",
    "    def add_features(self, res):\n",
    "        self.counter_print()\n",
    "        fs,x = res\n",
    "        diff = (self.limit_to*fs)-x.shape[0]\n",
    "        if self.pad == 'resize':\n",
    "            x = np.resize(x,(fs*self.limit_to,))\n",
    "        elif self.pad == 'zero':\n",
    "            x = np.hstack([np.zeros(diff), x]) if diff>0 else x[:(self.limit_to*fs)]\n",
    "        else:\n",
    "            x = np.hstack([np.repeat(x.mean(), diff), x]) if diff>0 else x[:(self.limit_to*fs)]\n",
    "            \n",
    "        s,t = aF.stFeatureExtraction(x,fs,self.frame_size*fs,self.frame_step*fs)\n",
    "        s = s.T.reshape(-1)\n",
    "        return s\n",
    "    \n",
    "    def add_features_functionals(self, res):\n",
    "        self.counter_print()\n",
    "        fs,x = res\n",
    "        s,t = aF.stFeatureExtraction(x,fs,self.frame_size*fs,self.frame_step*fs)\n",
    "        summarized_functionals = np.hstack([\n",
    "            s.mean(axis=1), \n",
    "            s.min(axis=1), \n",
    "            s.max(axis=1), \n",
    "            s.std(axis=1),\n",
    "            s.var(axis=1),\n",
    "            skew(s, axis=1),\n",
    "            kurtosis(s, axis=1)\n",
    "            \n",
    "        ])\n",
    "        return summarized_functionals\n",
    "\n",
    "    \n",
    "class PyAudioAnalysisFeatures(PyAudioAnalysisFeaturesFactory, BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        PyAudioAnalysisFeaturesFactory.__init__(self, **kwargs)\n",
    "        \n",
    "    def fit(self):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_base = feature_dict[self.key]\n",
    "        return X_base.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 800 850 900 950 1000 1050 1100 1150 1200 1250 1300 1350 1400 1450 1500 1550 1600 1650 1700 1750 1800 1850 1900 1950 2000 2050 2100 2150 2200 2250 2300 2350 2400 2450 2500 2550 2600 2650 2700 2750 2800 2850 2900 2950 3000 3050 3100 3150 3200 3250 3300 "
     ]
    }
   ],
   "source": [
    "paaff_zero_pad = PyAudioAnalysisFeaturesFactory(pad='zero', keep_duration=False)\n",
    "X_train_zero = paaff_zero_pad.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_zero_np = X_train_zero.values.reshape(X_train_zero.shape[0], 34, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_data/'X_train_zero_np.npy', X_train_zero_np)\n",
    "np.save(path_data/'y_train.npy', y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 800 850 900 950 1000 1050 1100 1150 1200 1250 1300 1350 1400 1450 1500 1550 1600 1650 1700 1750 1800 1850 1900 1950 2000 2050 2100 2150 2200 2250 2300 2350 2400 2450 2500 2550 2600 2650 2700 2750 2800 2850 2900 2950 3000 3050 3100 3150 3200 3250 3300 "
     ]
    }
   ],
   "source": [
    "# feature_dict = dict()\n",
    "paaff = PyAudioAnalysisFeaturesFactory(pad='stat')\n",
    "X_train_summary = paaff.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3350 3400 3450 3500 3550 3600 3650 3700 3750 3800 3850 3900 3950 4000 4050 4100 4150 4200 4250 4300 "
     ]
    }
   ],
   "source": [
    "X_test_summary = paaff.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4350 4400 4450 4500 4550 4600 4650 4700 4750 4800 4850 4900 4950 5000 5050 5100 5150 5200 5250 5300 5350 5400 5450 5500 5550 5600 5650 5700 5750 5800 5850 5900 5950 6000 6050 6100 6150 6200 6250 6300 6350 6400 6450 6500 6550 6600 6650 6700 6750 6800 6850 6900 6950 7000 7050 7100 7150 7200 7250 7300 "
     ]
    }
   ],
   "source": [
    "X_devel_summary = paaff.fit_transform(X_devel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_summary.to_csv(path_data/'X_train_summary.csv')\n",
    "X_test_summary.to_csv(path_data/'X_test_summary.csv')\n",
    "X_devel_summary.to_csv(path_data/'X_devel_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral    2287\n",
       "happy       743\n",
       "sad         187\n",
       "angry       125\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gurudev/anaconda3/lib/python3.6/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (10000) in class sad will be larger than the number of samples in the majority class (class #neutral -> 2287)\n",
      "  n_samples_majority))\n",
      "/home/gurudev/anaconda3/lib/python3.6/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (10000) in class angry will be larger than the number of samples in the majority class (class #neutral -> 2287)\n",
      "  n_samples_majority))\n"
     ]
    }
   ],
   "source": [
    "# model = AdaBoostClassifier(DecisionTreeClassifier(), \n",
    "#                                  n_estimators=10, learning_rate=1.0)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "n = 500\n",
    "model = Pipeline([\n",
    "    ('oversampling', RandomOverSampler(sampling_strategy=\n",
    "                                        {'neutral': 2287, \n",
    "                                          'happy': 743, \n",
    "                                          'sad': 10000, \n",
    "                                          'angry': 10000})),\n",
    "    ('model', AdaBoostClassifier(SVC(probability=True, \n",
    "                                     gamma='auto'), \n",
    "                                 n_estimators=1, \n",
    "                                 learning_rate=1.0))\n",
    "#     ('model', DecisionTreeClassifier(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "model.fit(X_train_summary, y_train) #.drop('duration', axis=1)\n",
    "y_predtree = model.predict(X_devel_summary)\n",
    "reporting(y_devel,y_predtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predtree = model.predict(X_tr_dl.drop('duration', axis=1))\n",
    "# reporting(y_tr_dl,y_predtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5903fc9f3599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#                         iid=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \"\"\"\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_pipeline = pipeline.Pipeline([\n",
    "    ('features', PyAudioAnalysisFeatures()),\n",
    "    ('pca', PCA(n_components=500)),\n",
    "    ('model', AdaBoostClassifier(DecisionTreeClassifier(class_weight={'neutral': 100000, \n",
    "                                                                      'happy': 100, \n",
    "                                                                      'sad': 1, \n",
    "                                                                      'angry':1}), \n",
    "                                 n_estimators=100, learning_rate=10.0))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': [15, 50, 100, 250, 500],\n",
    "    'model__class_weight': [\n",
    "                        {'neutral': 1, 'happy': 1, 'sad': 100000, 'angry':100000},\n",
    "                        {'neutral': 100000, 'happy': 100000, 'sad': 1, 'angry':1}\n",
    "                    ],\n",
    "    'model__learning_rate': [0.1, 1, 10.0]\n",
    "}\n",
    "\n",
    "for k,v in feature_transform_params:\n",
    "    param_grid['features__'+k] = v\n",
    "    \n",
    "# custom scoring - Unweighted Average Recall (from the paper),  \n",
    "# because our data is imbalanced\n",
    "uar = make_scorer(recall_score, average='macro')\n",
    "\n",
    "model_pipeline_cv = GridSearchCV(\n",
    "    estimator= model_pipeline, #use the model\n",
    "    param_grid=param_grid, # generate combinations from the parameter grid\n",
    "    scoring=uar, #UAR to pick the best params\n",
    "    n_jobs=4, # use these many cores for faster parallel processing\n",
    "    cv=5, # k fold cv\n",
    "    refit=True, # refit the best parameters on all of the data\n",
    "    verbose=50, #give detailed progress\n",
    "    iid=True)\n",
    "\n",
    "model_pipeline_cv.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=False):\n",
    "    \n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def reporting(y_test,y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(cm, target_names=np.unique(y_train))\n",
    "    print(confusion_matrix)\n",
    "    print(\"\\n\",classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "456.997px",
    "left": "1634px",
    "right": "20px",
    "top": "115px",
    "width": "322.969px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
